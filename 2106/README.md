# Michael's Reading Notes (June 2021)
[Back to home](../README.md)

## By Date

### June 24, 2021

#### Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks
Authors: *Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, Noah A. Smith*

Topics: roberta, language models, fine-tuning, pre-training

[My Summary](r/24-gururangan-don’t.md)

### June 7, 2021

#### Exploring Transfer Learning For End-to-End Spoken Language Understanding
Authors: *Subendhu Rongali, Beiye Liu, Liwei Cai, Konstantine Arkoudas, Chengwei Su, Wael Hamza*

Topics: end-to-end SLU, spoken language understanding, transformer, joint decoder

[My Summary](r/07-rongali-exploring.md)

### June 6, 2021

#### FreeLB: Enhanced Adversarial Training for Natural Language Understanding
Authors: *Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, Jingjing Liu*

Topics: adversarial training, language models

[My Summary](r/06-zhu-freelb:.md)

### June 5, 2021

#### Characterizing English Variation across Social Media Communities with BERT
Authors: *Li Lucy, David Bamman*

Topics: sociolinguistics, social media, NLP, BERT

[My Summary](r/05-lucy-characterizing.md)

#### Limitations of Autoregressive Models and Their Alternatives
Authors: *Chu-Cheng Lin, Aaron Jaech, Xin Li, Matthew R. Gormley, Jason Eisner*

Topics: theoretical CS, NLP, language models, autoregressive, proofs

[My Summary](r/05-lin-limitations.md)

